version: '3'

services:
  # Services only needed for local development
  postgres:
    build: docker/local_postgres
    environment:
      - POSTGRES_USER=deploy
      - POSTGRES_PASSWORD=deploy
      - POSTGRES_DB=openledger
      - PGUSER=deploy
      - PGDATABASE=openledger
    env_file: .env
    ports:
      - "5434:5432"
    volumes:
      - postgres:/var/lib/postgresql/data

  s3:
    image: minio/minio:latest
    ports:
      - "5010:5000"
      - "5011:5001"
    env_file:
      - .env
    environment:
      MINIO_ROOT_USER: ${AWS_ACCESS_KEY}
      MINIO_ROOT_PASSWORD: ${AWS_SECRET_KEY}
      # Comma separated list of buckets to create on startup
      BUCKETS_TO_CREATE: ${OPENVERSE_BUCKET},openverse-airflow-logs,commonsmapper-v2,commonsmapper,inaturalist-open-data
    # Create the buckets on every container startup
    # Is there something about creating the buckets in the entrypoint that might make them
    # visible as buckets, as opposed to syncing them over from the volume? Doesn't seem likely,
    # so maybe this could be dropped in favor of fixed empty subdirectories?
    # Note: $0 is included in the exec because "/bin/bash -c" swallows the first
    # argument, so it must be re-added at the beginning of the exec call
    entrypoint: >-
      /bin/bash -c
      "for b in $${BUCKETS_TO_CREATE//,/ }; do
        echo \"Making bucket $$b\" && mkdir -p /data/$$b;
      done &&
      exec $$0 \"$$@\""
    command: minio server /data --address :5000 --console-address :5001
    volumes:
      # Any buckets used for testing provider data imported from s3 should be subdirectories under 
      # /tests/s3-data/
      # The trick to the issues here (https://wordpress.slack.com/archives/C02012JB00N/p1655118749223179)
      # was to have a single volume, and to represent each bucket as a subdirectory under that.
      # BUT, the test runs still can't see the inaturalist-open-data bucket, even though I have 
      # verified through docker that the files exist on the container.
      # TO DO: The openverse user has root access to all buckets on this minio instance, which
      # makes sense for openverse-owned buckets, but not for read-only buckets owned by providers.
      # Maybe we add a minio/mc + minio/minio pair with more realistic permissions for buckets
      # containing sample provider data?
      - ./tests/s3-data:/data:rw
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5010/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Dev changes for the webserver container
  webserver:
    depends_on:
      - postgres
      - s3
    build:
      context: .
      args:
        - REQUIREMENTS_FILE=requirements_dev.txt
      dockerfile: docker/airflow/Dockerfile
    restart: on-failure
    # This command ensures an admin account is created on startup
    command: init
    volumes:
      - ./openverse_catalog:/usr/local/airflow/openverse_catalog

volumes:
  postgres:
  minio:
